{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.LeNet-5（1994年）\n",
    "\n",
    "**学习目标**\n",
    "\n",
    "1. 熟悉CNN模型中的卷积层和池化层（汇聚层）\n",
    "\n",
    "2. 掌握LeNet模型的构建方法\n",
    "\n",
    "3. 熟悉Adam优化器的使用\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多层感知机是一种强大的神经网络模型，能够学习复杂的非线性映射关系，但它在处理图像数据时存在很大的局限性。MLP的输入层神经元数量通常等于输入数据的特征维度，图像数据的特征维度可能非常大（例如，1000x1000 的彩色图像有300万个像素），如果直接将图像展开为向量输入到MLP中，会导致模型参数数量急剧增加，计算成本高且容易过拟合。\n",
    "\n",
    "另外，MLP 将输入数据视为一维向量，忽略了图像中的空间结构（如局部特征和空间关系）。图像中的像素通常具有局部相关性（例如，相邻像素通常属于同一物体或纹理），而 MLP 无法有效利用这种局部信息。\n",
    "\n",
    "CNN 的发展是为了解决 MLP 在处理图像数据时的局限性，尤其是参数过多、缺乏空间结构感知和计算效率低的问题。通过局部连接、权值共享、层次化特征提取和池化操作，CNN 能够高效地提取图像的局部和全局特征，并在图像分类、目标检测、图像分割等任务中取得了显著的成功。因此，CNN 成为了深度学习在计算机视觉领域的重要模型。\n",
    "\n",
    "### 5.1 卷积神经网络（CNN）\n",
    "\n",
    "1、CNN的发展历史\n",
    "\n",
    "1980年，日本科学家Kunihiko Fukushima设计了一个多层神经网络模型Neocognitron，具有类似卷积和池化的操作。它模拟了生物视觉系统中的层次化特征提取过程。Neocognitron 为 CNN 的结构奠定了基础，但当时并未引起广泛关注。\n",
    "\n",
    "1998年，Yann LeCun、Yoshua Bengio 和 Leon Bottou设计的LeNet-5 是第一个成功应用于实际任务的 CNN 模型，主要用于手写数字识别（如邮政编码识别）。LeNet-5 包含卷积层、池化层和全连接层，使用 Sigmoid 激活函数和平均池化。LeNet-5 证明了 CNN 在实际任务中的有效性，为后续研究奠定了基础。\n",
    "\n",
    "在 2000 年代初期，由于计算资源的限制和数据集的规模较小，CNN 的研究进入了低谷期。尽管如此，一些研究者仍在继续探索 CNN 的潜力。\n",
    "\n",
    "2012年，Alex Krizhevsky、Ilya Sutskever 和 Geoffrey Hinton设计的 AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了突破性成绩，错误率从 26% 降低到 15.3%。AlexNet 包含 5 个卷积层和 3 个全连接层，使用 ReLU 激活函数和 Dropout 正则化技术。\n",
    "AlexNet 的成功标志着深度学习在计算机视觉领域的复兴，推动了 CNN 的广泛应用。\n",
    "\n",
    "2014年，VGG的Karen Simonyan 和 Andrew Zisserman设计的 VGGNet 通过使用更小的卷积核（3x3）和更深的网络结构（16-19 层），在 ILSVRC 中取得了优异成绩。VGGNet 证明了深度对 CNN 性能的重要性，并成为后续模型的基础。\n",
    "\n",
    "2015年，微软亚洲研究院的 Kaiming He、Xiangyu Zhang、Shaoqing Ren 和 Jian Sun 等人提出了 ResNet，这是一种残差连接（Residual Connection）结构，能够有效地解决梯度消失和梯度爆炸问题，使得网络深度可以达到 100 层以上。ResNet 在 ILSVRC 中取得了 3.57% 的错误率，超越了人类水平，成为深度学习的重要里程碑。ResNet 被认为是深度学习领域里最重要的模型之一。它在多个任务上都取得了不错的成绩，并被认为是深度学习领域里最具创新性的模型之一。\n",
    "\n",
    "ResNet 之后，许多研究者提出了许多改进的 CNN 模型，如 DenseNet、MobileNet、EfficientNet 等。这些模型都试图通过减少参数数量、提高计算效率和改善模型性能来提升 CNN 的性能。\n",
    "\n",
    "2016年，Gao Huang、Zhuang Liu 和 Laurens van der Maaten等人提出的 DenseNet 继承了 ResNet 的思想，通过密集连接（Dense Connection）将每一层的输出直接连接到后续所有层，增强了特征的重用和梯度的流动。DenseNet 在保持高性能的同时，减少了参数数量和计算复杂度。\n",
    "\n",
    "2017年，Google的Andrew G. Howard 等人设计的 MobileNet 引入了深度可分离卷积（Depthwise Separable Convolution），显著减少了计算量和参数数量，适合移动设备和嵌入式系统。MobileNet 推动了轻量级 CNN 的发展，使其能够在资源受限的设备上运行。\n",
    "\n",
    "3.6 EfficientNet（2019）\n",
    "2019年，Google的Mingxing Tan 和 Quoc V. Le 等人设计的 EfficientNet 通过复合缩放（Compound Scaling）同时调整网络的深度、宽度和分辨率，实现了在计算效率和性能之间的平衡。EfficientNet 在多个任务中表现优异，成为高效 CNN 的代表。\n",
    "\n",
    "2、 CNN的优势\n",
    "\n",
    "（1）空间不变性（Spatial Invariance）：卷积层的权重共享特性使得网络能够学习到对输入图像中物体位置变化不敏感的特征，这是MLP所不具备的。\n",
    "\n",
    "（2）多尺度特征学习：通过堆叠多个卷积层和池化层，LeNet能够学习从低级到高级的多尺度特征表示。\n",
    "\n",
    "（3）自动特征提取：与MLP相比，LeNet不需要手动设计特征提取方法，它能够自动从数据中学习特征。\n",
    "\n",
    "（4）更小的模型尺寸：由于权重共享和池化操作，LeNet模型的参数数量远小于具有相同深度的全连接MLP。\n",
    "\n",
    "3、CNN的应用\n",
    "\n",
    "随着 CNN 的发展，其应用范围不断扩展，远远超出了图像分类的范围，包括：\n",
    "\n",
    "图像分类：AlexNet、VGGNet、GoogLeNet、ResNet。\n",
    "\n",
    "目标检测：R-CNN、Fast R-CNN、Faster R-CNN 和 YOLO 系列。\n",
    "\n",
    "图像分割：U-Net、Mask R-CNN。\n",
    "\n",
    "人脸识别：FaceNet、DeepFace。\n",
    "\n",
    "医学影像分析：癌症检测、器官分割。\n",
    "\n",
    "自动驾驶：感知系统中的物体检测和车道识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 LeNet-5概述\n",
    "\n",
    "LeNet是卷积神经网络（CNN）的早期代表之一，由Yann LeCun等人开发，用于手写数字识别任务。\n",
    "\n",
    "1989年，Yann LeCun等人在贝尔实验室首次将反向传播算法成功应用于识别美国邮政服务提供的手写邮政编码数字，并且认为通过提供来自任务域的约束可以增强学习网络的泛化能力。他将使用反向传播算法训练的卷积神经网络结合到读取手写数字上，这即是后来被称为LeNet的雏形。\n",
    "\n",
    "同年，Yann LeCun在发表的另一篇论文中描述了一个小的手写数字识别问题，并且表明即使该问题是线性可分的，单层网络也表现出较差的泛化能力。而当在多层的、有约束的网络上使用有位移不变性的特征检测器（shift invariant feature detectors）时，该模型可以在此任务上表现得非常好。他认为这些结果证明了将神经网络中的自由参数数量最小化可以增强神经网络的泛化能力。\n",
    "\n",
    "1990年，他们发表的论文再次描述了反向传播网络在手写数字识别中的应用，他们仅对数据进行了最小限度的预处理，而模型则是针对这项任务精心设计的，并且对其进行了高度约束。输入数据由图像组成，每张图像上包含一个数字，在美国邮政服务提供的邮政编码数字数据上的测试结果显示该模型的错误率仅有1%，拒绝率约为9%。（LeNet-1）\n",
    "\n",
    "在多年的研究和许多次成功的迭代后，这项由Yann LeCun在1994年完成的开拓性成果被命名为LeNet-5。\n",
    "\n",
    "1998年，Yann LeCun，Leon Bottou，Yoshua Bengio和Patrick Haffner在合作发表的论文中回顾了应用于手写字符识别的各种方法，并用标准手写数字识别基准任务对这些模型进行了比较，证明了卷积神经网络在该任务上的优势。他们同时还提供了许多神经网络实际应用的例子，如两种用于在线识别手写字符的系统和能每天读取数百万张支票的模型。\n",
    "\n",
    "LeNet-5因其在手写数字识别上的成功应用而成为深度学习和计算机视觉领域的一个里程碑，Yann LeCun因此被誉为卷积神经网络之父。虽然LeNet-5的架构相对简单，但它为后来更复杂的CNN架构奠定了基础，如AlexNet等，后者在2012年的ImageNet竞赛中取得了突破性的成绩，重新点燃了对深度学习和CNN研究的兴趣。\n",
    "\n",
    "LeNet-5标志着深度学习在图像识别领域的起步和发展，其设计思想和架构对后续的神经网络设计产生了深远的影响。\n",
    "\n",
    "LeNet-5的创新设计为深度学习和卷积神经网络的发展奠定了基础，尤其是在图像识别和计算机视觉领域。尽管LeNet的架构相对简单，但它在深度学习历史上具有里程碑意义。随着技术的发展，更深、更复杂的CNN架构如AlexNet、VGGNet、ResNet等相继出现，进一步推动了深度学习在多个领域的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 LeNet-5的结构\n",
    "\n",
    "LeNet-5 的结构如下图所示： \n",
    "\n",
    "<img src=\"./images/LeNet-5.png\" style=\"zoom:100%;\" />\n",
    "\n",
    "- 输入：输入图像大小为32 × 32 x 1，即32 × 32像素的灰度图像。\n",
    "- **C1 卷积层**：使用6个5 × 5的滤波器，得到6组大小为28 × 28 = 784的特征映射。因此，C1层的神经元数量为6 × 784 = 4,704，可训练参数 数量为6 × 25 + 6 = 156，连接数为156 × 784 = 122,304（包括偏置在内， 下同）。\n",
    "- **S2 汇聚层**：采样窗口为2×2，使用平均汇聚，并使用一个非线性函数。神经元个数为6 × 14 × 14 = 1,176，可训练参数数量为6 × (1 + 1) = 12，连接数为6 × 196 × (4 + 1) = 5,880。\n",
    "- **C3 卷积层**：LeNet-5中用一个连接表来定义输入和输出特征映射之间 的依赖关系，如图5.11所示，共使用60个5×5的滤波器，得到16组大小 为10×10的特征映射。神经元数量为16×100 = 1,600，可训练参数数量为(60 × 25) + 16 = 1,516，连接数为100 × 1,516 = 151,600。 (如果不使用连接表，则需要 96个5 × 5的滤波器)。\n",
    "- **S4 汇聚层**：采样窗口为2 × 2，得到16个5 × 5大小的特征映射， 可训练参数数量为16 × 2 = 32，连接数为16 × 25 × (4 + 1) = 2000。\n",
    "- **C5 卷积层**：使用120 × 16 = 1,920个5 × 5的滤波器，得到120 组大小为1 × 1的特征映射。C5层的神经元数量为120，可训练参数数量 为1,920 × 25 + 120 = 48,120，连接数为120 × (16 × 25 + 1) = 48,120。\n",
    "- **F6 全连接层**：有84个神经元，可训练参数数量为84×(120+1) = 10,164。连接数和可训练参数个数相同，为10,164。\n",
    "- 输出：输出层由10个欧氏径向基函数（Radial Basis Function，RBF） 函数组成。\n",
    "\n",
    "上述这些数据是如何计算出来的呢？这里我们就需要了解卷积层和池化层是如何工作的。\n",
    "\n",
    "### 5.4 LeNet-5的关键技术\n",
    "\n",
    "与多层感知器（MLP）相比，LeNet-5引入了一些关键技术：\n",
    "\n",
    "1、卷积层（Convolutional Layer）\n",
    "\n",
    "卷积层通过使用小的滤波器（或称为卷积核）在输入图像上滑动，提取局部特征，如边缘、纹理等。\n",
    "\n",
    "【待定】\n",
    "\n",
    "2、池化层（Pooling Layer）（汇聚层）\n",
    "\n",
    "池化层也称为下采样层（Subsampling Layer），用于降低特征图的空间维度，从而减少参数数量和计算量，同时使特征检测更加鲁棒。\n",
    "\n",
    "【待定】\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 LeNet-5模型的应用——手写数字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.导入必需的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.数据集的加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义转换操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练集和测试集\n",
    "train_dataset = datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）构建LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): Sigmoid()\n",
      "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (4): Sigmoid()\n",
      "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (8): Sigmoid()\n",
      "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (10): Sigmoid()\n",
      "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), \n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), \n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), \n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), \n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Conv2d 是 PyTorch 中的一个模块，它代表了一个 2D 卷积层，广泛应用于卷积神经网络（CNNs）中。2D 卷积层对输入的 2D 数据（通常是图像）进行卷积操作，可以用于提取特征。\n",
    "\n",
    "nn.Conv2d 的关键参数：\n",
    "\n",
    "in_channels：输入数据的通道数。例如，RGB 图像有 3 个通道。\n",
    "\n",
    "out_channels：输出数据的通道数，也是卷积层中卷积核（过滤器）的数量。\n",
    "\n",
    "kernel_size：卷积核的大小。可以是一个整数或者一个元组指定高度和宽度，例如 3 或者 (3, 3)。\n",
    "\n",
    "stride（步长）：卷积核滑动的步长。默认为 1。\n",
    "\n",
    "padding（填充）：给输入的四周添加填充。默认为 0，可以是一个整数或者一个元组来分别指定上下和左右的填充。\n",
    "\n",
    "dilation（扩张）：卷积核的扩张率。默认为 1，用于控制卷积核覆盖的输入区域。\n",
    "\n",
    "groups：分组卷积的数量。默认为 1，用于实现深度可分离卷积等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.AvgPool2d 是 PyTorch 中的一个模块，它代表了一个 2D 平均池化层（Average Pooling Layer），用于对输入数据进行池化操作。池化是一种降低数据维度的方法，通常用于减少卷积神经网络（CNN）中的参数数量和计算量，同时使特征检测更加鲁棒。\n",
    "\n",
    "nn.AvgPool2d 的关键参数：\n",
    "\n",
    "kernel_size：池化窗口的大小。可以是一个整数或者一个元组指定高度和宽度，例如 2 或者 (2, 2)。\n",
    "\n",
    "stride（步长）：池化窗口滑动的步长。默认与 kernel_size 相同，但也可以根据需要设置不同的值。\n",
    "\n",
    "padding（填充）：给输入的四周添加填充。默认为 0，可以是一个整数或者一个元组来分别指定上下和左右的填充。\n",
    "\n",
    "平均池化层会计算每个窗口内的平均值，并将这个值输出到相应的位置。这有助于降低特征图的尺寸，同时保留重要的信息。\n",
    "\n",
    "我们创建的 AvgPool2d 层，其 kernel_size 和 stride 都设置为 2，这意味着池化窗口大小为 2x2，并且每次滑动步长为 2 个像素。应用这个池化层后，输出的特征图尺寸高度和宽度都减半了。\n",
    "\n",
    "池化层通常用于卷积层之后，以减少特征图的尺寸，从而减少参数数量和计算量，同时使网络对小的位置变化更加鲁棒。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim.Adam 是 PyTorch 中的一个优化器类，代表 Adam（Adaptive Moment Estimation）优化算法。Adam 是一种流行的梯度下降优化算法，因其自适应学习率的特点而广泛用于训练深度学习模型。它结合了动量（Momentum）和 RMSprop 的概念，旨在在各种问题上提供稳定的性能。\n",
    "\n",
    "torch.optim.Adam 的关键参数：\n",
    "\n",
    "params：需要优化的参数列表。\n",
    "\n",
    "lr（学习率）：算法中用于更新参数的步长。默认值是 0.001。\n",
    "\n",
    "betas：两个浮点数，分别代表用于计算梯度指数移动平均的系数（即动量和平方项的指数衰减率）。默认值是 (0.9, 0.999)。\n",
    "\n",
    "eps：一个很小的数，用于数值稳定性，防止分母为零。默认值是 1e-8。\n",
    "\n",
    "weight_decay：权重衰减项，用于正则化以减少过拟合。默认值是 0。\n",
    "\n",
    "amsgrad：一个布尔值，如果设置为 True，则使用 AMSGrad 变体。AMSGrad 确保在非平稳目标的情况下，Adam 优化器也能收敛到全局最优。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.99430\n",
      "Epoch [2/10], Loss: 0.22064\n",
      "Epoch [3/10], Loss: 0.14568\n",
      "Epoch [4/10], Loss: 0.11319\n",
      "Epoch [5/10], Loss: 0.09298\n",
      "Epoch [6/10], Loss: 0.08008\n",
      "Epoch [7/10], Loss: 0.06992\n",
      "Epoch [8/10], Loss: 0.06179\n",
      "Epoch [9/10], Loss: 0.05665\n",
      "Epoch [10/10], Loss: 0.05198\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0  # 初始化总损失累加器\n",
    "    \n",
    "    for data, labels in train_loader:\n",
    "        \n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()  # 累加损失值\n",
    "\n",
    "    # 计算平均损失并打印\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.03%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, labels in test_loader:\n",
    "        \n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
