{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.AlexNet（2012年）\n",
    "\n",
    "**学习目标**\n",
    "\n",
    "1. 熟练使用torchvision.transforms进行数据增强\n",
    "\n",
    "2. 熟练使用torchvision.datasets.ImageFolder加载图像数据集\n",
    "\n",
    "3. 熟练使用ReLU激活函数\n",
    "\n",
    "4. 熟悉Dropout技术在模型中的使用\n",
    "\n",
    "5. 会使用GPU训练模型\n",
    "\n",
    "6. 熟悉随机梯度下降（SGD）优化器的使用\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 AlexNet\n",
    "\n",
    "在LeNet提出后，卷积神经网络虽然在计算机视觉和机器学习领域中很有名气，但并没有主导人工智能领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。\n",
    "\n",
    "2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。AlexNet和LeNet的架构非常相似，但也存在显著差异。\n",
    "- AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "- AlexNet使用ReLU而不是sigmoid作为其激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 ImageNet数据集\n",
    "\n",
    "ImageNet 是一个大型的图像数据库，它旨在用于视觉对象识别软件的研究，这个项目由斯坦福大学的研究者和其他国际合作者共同创建。ImageNet拥有超过1400万的经过标注的图像，涵盖了超过2万个类别，其中每个类别中的图像都是从互联网上收集而来，并由人工进行核实与标注的。\n",
    "\n",
    "ImageNet特别著名的是它的规模和多样性，这使得它成为了计算机视觉和机器学习领域中最重要的数据集之一。特别是，ImageNet Large Scale Visual Recognition Challenge (ILSVRC)，一个自2010年以来每年举办的竞赛，对于推动深度学习和卷积神经网络（CNN）在图像识别领域的发展起到了关键作用。\n",
    "\n",
    "在ILSVRC中，研究者们会使用ImageNet的一个子集来训练和测试他们的算法，这个子集包括1000个类别，每个类别大约有1000张图像。许多现代的图像识别模型，例如AlexNet、VGGNet、GoogLeNet和ResNet等，都是在这个挑战赛中被提出并证明其有效性的。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 ImageNet竞赛\n",
    "\n",
    "全称为ImageNet Large Scale Visual Recognition Challenge (ILSVRC)，是机器视觉领域中一项非常著名的学术竞赛。它由斯坦福大学李飞飞教授主导，自2010年开始举办，至2017年结束。竞赛使用的ImageNet数据集包含了超过1400万张全尺寸的有标记图片，涉及22,000个类别。ILSVRC竞赛的主要目标是评估大规模对象检测和图像分类的算法，推动计算机视觉技术的发展。\n",
    "\n",
    "竞赛项目包括图像分类、目标定位、目标检测、视频目标检测和场景分类等任务。例如，在图像分类任务中，参赛者需要识别图片中物体所属的1000个分类之一，通常使用top-5错误率作为评估标准。2012年，AlexNet的出现将错误率从26%降低到了16%。2016年，\"搜神\"（Trimps-Soushen）代表队将错误率进一步降低到2.9%。\n",
    "\n",
    "ILSVRC竞赛不仅推动了深度学习在计算机视觉领域的应用，也见证了许多经典网络结构的诞生，如AlexNet、VGG、Inception、ResNet等。2017年7月，随着最后一届挑战赛成绩的公布，李飞飞教授宣布ImageNet挑战赛将转由Kaggle主办。\n",
    "\n",
    "总的来说，ImageNet竞赛对于推动计算机视觉和深度学习技术的发展起到了重要作用，同时也为研究人员提供了一个宝贵的比较和测试算法的平台。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 AlexNet的关键技术\n",
    "\n",
    "AlexNet对于LeNet的一些关键改进包括：\n",
    "\n",
    "（1）ReLU激活函数\n",
    "AlexNet采用ReLU激活函数代替LeNet中的Sigmoid或Tanh函数，这简化了计算并且有助于缓解梯度消失问题。\n",
    "\n",
    "（2）数据增强\n",
    "AlexNet在训练时使用了图像增强技术，如翻转、裁切和变色，以扩充数据集并减少过拟合。\n",
    "\n",
    "（3）Dropout正则化\n",
    "AlexNet引入了Dropout技术来抑制过拟合，提高模型的泛化能力。\n",
    "\n",
    "（4）更高效的训练策略\n",
    "AlexNet利用GPU进行训练，大幅提高了深度神经网络的性能。\n",
    "\n",
    "这些改进使得AlexNet在图像识别任务上的性能大大超越了LeNet，并推动了深度学习在计算机视觉领域的广泛应用。\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.5 基于AlexNet的水果蔬菜识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.导入必需的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **GPU的使用**\n",
    "\n",
    "⾃2000年以来，GPU性能每⼗年增⻓1000倍。很多大模型的训练，都需要GPU提供这样的性能。如果想使⽤NVIDIA GPU进⾏计算，⾸先需要确保计算机或服务器里⾄少安装了⼀个NVIDIA GPU。然后，下载NVIDIA显卡驱动和CUDA并按照提⽰设置适当的路径。当这些准备⼯作完成，就可以使⽤nvidia-smi命令来查看显卡信息。\n",
    "\n",
    "在PyTorch中，每个数组都有⼀个设备（device），我们通常将其称为上下⽂（context）。到⽬前为⽌，默认情况下，所有变量和相关的计算都分配给CPU。有时上下⽂可能是GPU。当我们跨多个服务器部署作业时，事情会变得更加棘⼿。通过智能地将数组分配给上下⽂，我们可以最⼤限度地减少在设备之间传输数据的时间。例如，当在带有GPU的服务器上训练神经⽹络时，我们通常希望模型的参数在GPU上。GPU的调用可以使用以下代码来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.数据集的加载和预处理\n",
    "\n",
    "transforms.Compose()类的主要作用是串联多个图像变换的操作。这段代码构建了训练集的图像变换操作train_transform和验证集的图像变换操作val_transform。下面分别来解释列表中每个参数的含义。\n",
    "\n",
    "- transforms.Resize((224,224))：  将原始图像尺寸缩放为 224 × 224 大小的输入图像；\n",
    "\n",
    "- transforms.RandomHorizontalFlip( )： 以给定的概率随机水平旋转给定的PIL的图像，默认为0.5；\n",
    "\n",
    "- transforms.RandomVerticalFlip( )： 以给定的概率随机垂直旋转给定的PIL的图像，默认为0.5；\n",
    "\n",
    "- transforms.ToTensor( )： 将给定图像转化为张量；\n",
    "\n",
    "- transforms.Normalize(）： 标准化处理，我们分别标准化RGB三个颜色通道中的每个通道，具体而⾔就是将通道的平均值从该通道的每个值中减去，然后将结果除以该通道的标准差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使⽤的水果蔬菜数据集包含了1400 张10个类别的图像。1000张图⽚⽤于训练，其余的则⽤于测试。解压下载的数据集后，我们获得了两个⽂件夹/Fruit-Images-Dataset-master/Training和/Fruit-Images-Dataset-master/Test。这两个⽂件夹都有很多个⼦⽂件夹，其中任何⼀个⽂件夹都包含相应类的图像。我们创建两个实例来分别读取训练和测试数据集中的所有图像⽂件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "train_dataset = torchvision.datasets.ImageFolder('./datasets/Fruit/train', train_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder('./datasets/Fruit/valid', val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.datasets.ImageFolder 是 PyTorch 的 torchvision.datasets 模块中的一个类，用于从文件夹中加载图像数据集。这种数据集的组织方式是，每个类别的图像存储在一个单独的子文件夹中。ImageFolder 类允许你以一种简单高效的方式加载这样的数据集，并将其用于训练或评估机器学习模型。\n",
    "\n",
    "torchvision.datasets.ImageFolder 的关键特性和用法：\n",
    "\n",
    "数据组织：数据集中的每个类别都有一个对应的文件夹，文件夹的名称通常被视为类别的名称，文件夹内包含该类别的所有图像。\n",
    "\n",
    "使用方式：你可以通过指定数据集的根目录来创建一个 ImageFolder 实例，它会自动地加载所有图像并创建一个数据集。\n",
    "\n",
    "转换：ImageFolder 接受一个 transform 参数，允许你定义一个图像预处理流程。这个转换流程可以是 torchvision.transforms 中的任何转换函数，例如 ToTensor、Resize、Normalize 等。\n",
    "\n",
    "数据加载：创建 ImageFolder 实例后，你可以使用 DataLoader 来批量加载数据，这在训练神经网络时非常有用。\n",
    "\n",
    "ImageFolder 是处理图像数据集的一个非常灵活的工具，尤其适用于那些图像已经按类别组织好的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader中的参数num_workers代表CPU线程的数量。\n",
    "\n",
    "DataLoader 是一个迭代器，它封装了数据和标签，可以批量地提供给模型进行训练或评估。DataLoader 的 pin_memory 参数是一个布尔值，用于控制是否将数据加载到锁页内存（pinned memory）中。\n",
    "\n",
    "锁页内存是一种特殊类型的内存，操作系统不会将其交换到磁盘，这通常用于加速将数据从主机内存复制到GPU内存的过程。当使用GPU进行训练时，如果设置 pin_memory=True，那么在数据加载阶段，DataLoader 会先将数据从主内存复制到锁页内存，然后再异步地将数据从锁页内存复制到GPU内存。\n",
    "\n",
    "使用 pin_memory 的好处包括：\n",
    "\n",
    "减少数据传输时间：由于锁页内存到GPU内存的数据传输可以异步进行，因此可以减少数据传输的等待时间。\n",
    "提高数据加载效率：使用锁页内存可以提高数据加载的效率，特别是当网络带宽是瓶颈时。\n",
    "然而，使用 pin_memory 也有一些注意事项：\n",
    "\n",
    "内存使用增加：因为数据需要同时存储在主内存和锁页内存中，所以会使用更多的内存。\n",
    "适用场景：当使用GPU进行训练时，设置 pin_memory=True 通常可以提高性能。但如果是CPU训练或者数据集非常小，使用锁页内存可能不会带来太大的好处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "# 获得训练数据集的类别\n",
    "num_category = len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "            # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "            # 另外，输出通道的数目远大于LeNet\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "            # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "            # 在前两个卷积层之后，池化层不用于减少输入的高度和宽度\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 5 * 5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU（Rectified Linear Unit）激活函数是一种广泛使用的非线性激活函数，特别是在深层神经网络中。ReLU函数的数学表达式非常简单：\n",
    "\n",
    "ReLU(x)=max(0,x)\n",
    "\n",
    "这意味着，如果输入x大于0，则输出就是x本身；如果输入x小于或等于0，则输出为0。这种函数形式在计算上非常高效，并且有助于缓解梯度消失问题，因为它的导数在正区间内是常数1。\n",
    "\n",
    "ReLU函数的优点：\n",
    "\n",
    "计算效率：由于其简单的阈值操作，ReLU在计算上非常快速。\n",
    "\n",
    "稀疏激活：由于其非线性特性，ReLU可以产生稀疏的激活，这意味着在任何给定时间，只有一部分神经元会激活，这有助于提高模型的表达能力。\n",
    "\n",
    "缓解梯度消失问题：在正区间内，ReLU的导数是1，这有助于在反向传播过程中保持梯度的大小，从而缓解梯度消失问题。\n",
    "\n",
    "ReLU的缺点：\n",
    "\n",
    "最明显的是死亡ReLU问题（Dead ReLU Problem），即当输入小于0时，ReLU的梯度为0，导致这部分神经元的权重在训练过程中不再更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(num_classes=num_category)\n",
    "# 将模型移动到设备上（GPU或者CPU）\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PyTorch中，.to(device) 是一个方法，用于将张量、模型或其他对象移动到指定的设备上，例如CPU或GPU。\n",
    "\n",
    "device 可以是一个指定的设备字符串，如 'cuda' 表示GPU，或者是一个具体的设备对象，如 torch.device('cuda:0')。\n",
    "\n",
    ".to(device) 可以将数据从当前设备移动到指定的设备，如果数据已经在目标设备上，它不会进行任何操作。\n",
    "\n",
    "调用 model.to(device) 时，模型的所有参数和缓冲区都会被移动到指定的设备。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在最初的AlexNet实现中，使用的优化器是带有动量的随机梯度下降（SGD with momentum）。动量项有助于加速SGD在优化过程中的收敛，尤其是在训练非常深的网络时。\n",
    "\n",
    "optim.SGD 是 PyTorch 中的一个类，代表随机梯度下降（Stochastic Gradient Descent）优化器。SGD 是一种常用的优化算法，用于调整神经网络的参数，以最小化损失函数。它是深度学习中最基本的优化方法之一。\n",
    "\n",
    "torch.optim.SGD 的关键参数：\n",
    "\n",
    "params：需要优化的参数列表。\n",
    "\n",
    "lr（学习率）：算法中用于更新参数的步长。\n",
    "\n",
    "momentum：动量项，用于加速梯度下降过程，特别是在训练初期。\n",
    "\n",
    "dampening：动量项的阻尼系数，可以防止更新过程中的数值不稳定。\n",
    "\n",
    "weight_decay：权重衰减项，用于正则化以减少过拟合。\n",
    "\n",
    "nesterov：如果设置为 True，则使用Nesterov动量，这是一种稍微改进的动量方法，可以提供更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Loss: 2.45399\n",
      "Epoch [2/80], Loss: 2.29800\n",
      "Epoch [3/80], Loss: 2.29519\n",
      "Epoch [4/80], Loss: 2.23684\n",
      "Epoch [5/80], Loss: 2.01853\n",
      "Epoch [6/80], Loss: 1.87071\n",
      "Epoch [7/80], Loss: 1.79351\n",
      "Epoch [8/80], Loss: 1.80497\n",
      "Epoch [9/80], Loss: 1.71596\n",
      "Epoch [10/80], Loss: 1.49393\n",
      "Epoch [11/80], Loss: 1.43154\n",
      "Epoch [12/80], Loss: 1.25664\n",
      "Epoch [13/80], Loss: 1.29308\n",
      "Epoch [14/80], Loss: 1.20167\n",
      "Epoch [15/80], Loss: 1.20551\n",
      "Epoch [16/80], Loss: 1.15314\n",
      "Epoch [17/80], Loss: 1.17617\n",
      "Epoch [18/80], Loss: 1.08774\n",
      "Epoch [19/80], Loss: 1.11247\n",
      "Epoch [20/80], Loss: 1.05547\n",
      "Epoch [21/80], Loss: 1.03198\n",
      "Epoch [22/80], Loss: 0.97292\n",
      "Epoch [23/80], Loss: 0.88345\n",
      "Epoch [24/80], Loss: 0.99121\n",
      "Epoch [25/80], Loss: 0.97391\n",
      "Epoch [26/80], Loss: 0.95221\n",
      "Epoch [27/80], Loss: 0.89670\n",
      "Epoch [28/80], Loss: 0.96731\n",
      "Epoch [29/80], Loss: 0.87555\n",
      "Epoch [30/80], Loss: 0.94413\n",
      "Epoch [31/80], Loss: 0.89062\n",
      "Epoch [32/80], Loss: 0.84500\n",
      "Epoch [33/80], Loss: 0.80129\n",
      "Epoch [34/80], Loss: 0.76135\n",
      "Epoch [35/80], Loss: 0.69076\n",
      "Epoch [36/80], Loss: 0.81787\n",
      "Epoch [37/80], Loss: 0.73188\n",
      "Epoch [38/80], Loss: 0.64963\n",
      "Epoch [39/80], Loss: 0.68696\n",
      "Epoch [40/80], Loss: 0.77432\n",
      "Epoch [41/80], Loss: 0.82285\n",
      "Epoch [42/80], Loss: 0.70420\n",
      "Epoch [43/80], Loss: 0.67830\n",
      "Epoch [44/80], Loss: 0.63642\n",
      "Epoch [45/80], Loss: 0.70414\n",
      "Epoch [46/80], Loss: 0.69201\n",
      "Epoch [47/80], Loss: 0.63754\n",
      "Epoch [48/80], Loss: 0.56206\n",
      "Epoch [49/80], Loss: 0.51541\n",
      "Epoch [50/80], Loss: 0.53792\n",
      "Epoch [51/80], Loss: 0.61348\n",
      "Epoch [52/80], Loss: 0.67514\n",
      "Epoch [53/80], Loss: 0.56677\n",
      "Epoch [54/80], Loss: 0.66299\n",
      "Epoch [55/80], Loss: 0.54958\n",
      "Epoch [56/80], Loss: 0.53047\n",
      "Epoch [57/80], Loss: 0.45573\n",
      "Epoch [58/80], Loss: 0.44867\n",
      "Epoch [59/80], Loss: 0.58263\n",
      "Epoch [60/80], Loss: 0.51368\n",
      "Epoch [61/80], Loss: 0.60592\n",
      "Epoch [62/80], Loss: 0.51674\n",
      "Epoch [63/80], Loss: 0.50047\n",
      "Epoch [64/80], Loss: 0.40945\n",
      "Epoch [65/80], Loss: 0.52084\n",
      "Epoch [66/80], Loss: 0.44507\n",
      "Epoch [67/80], Loss: 0.50897\n",
      "Epoch [68/80], Loss: 0.45598\n",
      "Epoch [69/80], Loss: 0.36200\n",
      "Epoch [70/80], Loss: 0.39380\n",
      "Epoch [71/80], Loss: 0.44793\n",
      "Epoch [72/80], Loss: 0.42858\n",
      "Epoch [73/80], Loss: 0.36016\n",
      "Epoch [74/80], Loss: 0.37931\n",
      "Epoch [75/80], Loss: 0.43675\n",
      "Epoch [76/80], Loss: 0.33406\n",
      "Epoch [77/80], Loss: 0.32089\n",
      "Epoch [78/80], Loss: 0.28358\n",
      "Epoch [79/80], Loss: 0.25708\n",
      "Epoch [80/80], Loss: 0.36471\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0  # 初始化总损失变量\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 将数据和标签移动到设备上（GPU或者CPU）\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()  # 累加损失值\n",
    "    \n",
    "    # 计算平均损失并打印\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.5f}')\n",
    "\n",
    "torch.save(model,'weights/alexnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test images: 91.67%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f\"Accuracy on test images: {(correct / total) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
