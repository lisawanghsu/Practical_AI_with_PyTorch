{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.注意力机制\n",
    "\n",
    "**学习目标**\n",
    "\n",
    "1. 了解注意力机制、缩放点积注意力、多头注意力和自注意力的概念\n",
    "\n",
    "2. 了解掩蔽softmax函数实现\n",
    "\n",
    "3. 了解缩放点积注意力的代码实现\n",
    "\n",
    "4. 了解多头注意力的代码实现\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 年 11 月，OpenAI 发布了 ChatGPT，迅速在产业界引起巨大波澜，自此，人工智能大模型时代拉开了序幕。ChatGPT 基于 **Transformer 架构**，具有强大的语言生成和理解能力。它能够模拟人类的对话方式，广泛应用于聊天、内容创作、编程辅助等领域。\n",
    "\n",
    "1、为什么要使用Transformer?\n",
    "\n",
    "CNN在图像识别领域取得了令人瞩目的成就，如ResNet、YOLO等在图像分类、目标检测领域都非常成功。但是在自然语言处理领域，CNN表现的相当糟糕，以至于完全无法使用CNN来处理自然语言。而传统的RNN、LSTM等模型在处理长序列时表现不佳，原因是它们的记忆能力有限，只能记住最近的输入信息，而远距离的上下文信息则难以捕捉。Transformer模型的出现正好解决了这个问题，它通过自注意力机制解决了长序列建模的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、什么是注意力机制？\n",
    "\n",
    "注意力机制（Attention Mechanism）是一种在深度学习中广泛使用的机制。视觉注意力机制是人类大脑的一种天生的能力。当我们看到一幅图片时，先是快速扫过图片，然后锁定需要重点关注的目标区域。比如当我们观察上述图片时，注意力很容易就集中在了人脸、文章标题和文章首句等位置。试想，如果每个局部信息都不放过，那么必然耗费很多精力，不利于人类的生存进化。同样地，在深度学习网络中引入类似的机制，可以简化模型，加速计算。另外，长距离“记忆”能力一直是个大难题，而引入“注意力机制”也能有效缓解这一问题。\n",
    "\n",
    "在实现上，注意力机制通常涉及计算一个查询（Query）、一组键（Key）和一组值（Value）之间的交互，然后根据这些交互生成加权的输出。\n",
    "\n",
    "注意力机制的基本思想是，模型能够通过注意力机制来选择性地聚焦于输入序列中的特定部分，从而提高模型的性能和解释性。具体来说，注意力机制可以分为以下几个步骤：\n",
    "\n",
    "（1）计算注意力权重：模型首先计算输入序列中每个元素与当前上下文的相关性，并将这些相关性作为权重分配给输入序列中的每个元素。\n",
    "\n",
    "（2）应用注意力权重：模型将注意力权重应用于输入序列，以聚焦于与当前任务最相关的部分。\n",
    "\n",
    "（3）生成输出：模型根据注意力权重生成输出，其中输出的选择性取决于输入序列中与当前上下文最相关的部分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "注意力机制的引入，为深度学习模型提供了一种强大的工具，以更有效地处理序列数据，特别是在需要考虑全局上下文信息的任务中。\n",
    "\n",
    "****\n",
    "下面我们就逐步构建出自注意力和多头注意力模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.注意力可视化函数\n",
    "\n",
    "为了更好的理解注意力机制，我们首先设计一个注意力可视化函数来绘制注意力矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，用于显示热图\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap='Reds'):\n",
    "    # 获取矩阵的行数和列数\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    # 创建一个图形和一组子图轴\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=True, \n",
    "                                 sharey=True, squeeze=False)\n",
    "    \n",
    "    # 遍历每一行的子图轴和对应的矩阵\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        # print(i, row_axes, row_matrices)\n",
    "        # 遍历每一行的子图轴和对应的矩阵\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            # print(j, ax, matrix)\n",
    "            # 在子图轴上显示矩阵的热图\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            # 如果是最后一行，则设置x轴标签\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            # 如果是第一列，则设置y轴标签\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            # 如果提供了标题，则设置子图的标题\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "                \n",
    "    # 为整个图形添加颜色条\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6)\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enumerate(zip(axes, matrices)) 是 Python 中的一种组合用法，用于同时遍历两个列表（或其他可迭代对象），并且还能获取每个元素的索引。\n",
    "\n",
    "1. zip(axes, matrices) 作用：将两个可迭代对象 axes 和 matrices 配对组合。生成一个包含元组的迭代器，每个元组由 axes 和 matrices 中对应位置的元素组成。\n",
    "\n",
    "示例1：\n",
    "\n",
    "如果 axes = ['a1', 'a2']，matrices = [[1, 2], [3, 4]]，那么 zip(axes, matrices) 会生成 [('a1', [1, 2]), ('a2', [3, 4])]。\n",
    "\n",
    "2. enumerate(...) 作用：为 zip(axes, matrices) 生成的每个元素添加一个索引。生成一个包含元组的迭代器，每个元组由索引和 zip(axes, matrices) 中的元素组成。\n",
    "\n",
    "示例2：\n",
    "\n",
    "如果 zip(axes, matrices) 生成 [('a1', [1, 2]), ('a2', [3, 4])]，那么 enumerate(zip(axes, matrices)) 会生成 [(0, ('a1', [1, 2])), (1, ('a2', [3, 4]))]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_weights = torch.eye(10).reshape((1, 1, 10, 10))\n",
    "show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.缩放点积注意力\n",
    "\n",
    "缩放点积注意力（Scaled Dot-Product Attention）是 Transformer 模型中的核心机制之一，用于计算输入序列中每个位置的注意力权重。它的公式如下：\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- Q：查询矩阵（Query），形状为 (n,dk)，表示 n个查询向量，每个向量的维度为 dk。\n",
    "- K：键矩阵（Key），形状为 (m,dk)，表示 m个键向量，每个向量的维度为 dk。\n",
    "- V：值矩阵（Value），形状为 (m,dv)，表示 m个值向量，每个向量的维度为 dv。\n",
    "- d：键和查询的维度。\n",
    "- sqrt(d)：缩放因子，用于防止点积结果过大。\n",
    "- softmax：对每一行进行归一化，得到注意力权重。\n",
    "\n",
    "下面我们来详细解释该公式：\n",
    "\n",
    "首先，计算查询矩阵 Q和键矩阵 K的转置 KT的点积。结果是一个形状为 (n,m)的矩阵，表示每个查询向量与每个键向量的相似度。\n",
    "\n",
    "其次，将点积结果除以sqrt(d)，目的是防止点积结果过大，导致 softmax 函数的梯度消失或爆炸。当 d较大时，点积结果的方差会增大，因此需要通过缩放来平衡。\n",
    "\n",
    "然后，进行对缩放后的点积矩阵的每一行进行 softmax 归一化，得到注意力权重矩阵。每一行的值表示一个查询向量对所有键向量的注意力权重，且每一行的权重之和为 1。\n",
    "\n",
    "最后，将注意力权重矩阵与值矩阵 V 相乘，得到最终的输出。计算结果是一个形状为 (n,dv)的矩阵，表示每个查询向量对应的加权值向量。\n",
    "\n",
    "根据分析可以得知，缩放点积注意力公式的作用是：\n",
    "\n",
    "1. 计算查询向量与键向量的相似度。\n",
    "2. 通过 softmax 归一化得到注意力权重。\n",
    "3. 根据注意力权重对值向量进行加权求和，得到最终输出。\n",
    "\n",
    "在该公式中，我们使用的softmax通常是一种被称为掩蔽softmax的函数，我们先来实现掩蔽softmax函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 掩蔽softmax函数，用于在softmax操作中屏蔽无效的数据\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\n",
    "        X:3D张量\n",
    "        valid_lens:1D张量, valid_lens.shape == torch.Size([X.shape[0]])\n",
    "        valid_lens:2D张量, valid_lens.shape == torch.Size([X.shape[0], X.shape[1]])\n",
    "    \"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    \n",
    "    else:\n",
    "        shape = X.shape\n",
    "        \n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "\n",
    "        X = X.reshape(-1, shape[-1])\n",
    "        arange_X = torch.arange((X.size(-1)), dtype=torch.float32, device=X.device)\n",
    "        # 将序列arange_X与valid_len进行比较，生成一个布尔类型的掩码\n",
    "        mask = arange_X[None, :] < valid_lens[:, None]\n",
    "        # print(f'MASK:\\n{mask} \\n X:\\n{X}')\n",
    "        X[~mask] = -1e6\n",
    "        \n",
    "        # 对掩蔽后的X应用softmax\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X[~mask]是一种高级索引（advanced indexing）的形式，用于根据布尔掩码 mask 从张量 X 中选择元素。这里的 ~ 操作符表示对 mask 进行按位取反操作，从而选择 mask 中为 False 的位置对应的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " masked softmax:\n",
      "\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4526, 0.5474, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3412, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4026, 0.4131, 0.1843, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3756, 0.4234, 0.2010, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 测试masked_softmax函数\n",
    "X = torch.rand(3, 2, 6)\n",
    "valid_lens = torch.tensor([1, 2, 3])\n",
    "\n",
    "print('\\n masked softmax:\\n')\n",
    "print(masked_softmax(X, valid_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在有了掩蔽softmax函数以后，我们就可以实现缩放点积注意力啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        # 查询、键和值的维度应相同\n",
    "        d = queries.shape[-1]\n",
    "        # 计算查询和键的点积，然后除以d的平方根进行缩放\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        # 应用掩蔽softmax获取注意力权重\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # 应用dropout并计算加权值\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试缩放点积注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " queries keys values:\n",
      "\n",
      "torch.Size([2, 10, 2])\n",
      "torch.Size([2, 10, 2])\n",
      "torch.Size([2, 10, 4])\n",
      "tensor([[[11.3451, 12.3451, 13.3451, 14.3451],\n",
      "         [11.4967, 12.4967, 13.4967, 14.4967],\n",
      "         [ 9.6025, 10.6025, 11.6025, 12.6025],\n",
      "         [10.0780, 11.0780, 12.0780, 13.0780],\n",
      "         [14.2400, 15.2400, 16.2400, 17.2400],\n",
      "         [ 9.9081, 10.9081, 11.9081, 12.9081],\n",
      "         [12.5453, 13.5453, 14.5453, 15.5453],\n",
      "         [11.8300, 12.8300, 13.8300, 14.8300],\n",
      "         [12.2373, 13.2373, 14.2373, 15.2373],\n",
      "         [11.8355, 12.8355, 13.8355, 14.8355]],\n",
      "\n",
      "        [[ 4.1968,  5.1968,  6.1968,  7.1968],\n",
      "         [ 5.2783,  6.2783,  7.2783,  8.2783],\n",
      "         [ 2.4953,  3.4953,  4.4953,  5.4953],\n",
      "         [ 4.8445,  5.8445,  6.8445,  7.8445],\n",
      "         [ 4.2992,  5.2992,  6.2992,  7.2992],\n",
      "         [ 3.0875,  4.0875,  5.0875,  6.0875],\n",
      "         [ 3.7612,  4.7612,  5.7612,  6.7612],\n",
      "         [ 7.5646,  8.5646,  9.5646, 10.5646],\n",
      "         [ 4.6555,  5.6555,  6.6555,  7.6555],\n",
      "         [ 5.6608,  6.6608,  7.6608,  8.6608]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 初始化查询、键和值的随机数据\n",
    "queries = torch.normal(0, 1, (2, 10, 2))\n",
    "keys = torch.normal(0, 1, (2, 10, 2))\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "\n",
    "# 打印查询、键和值的形状\n",
    "print(\"\\n queries keys values:\\n\")\n",
    "print(queries.shape)\n",
    "print(keys.shape)\n",
    "print(values.shape)\n",
    "\n",
    "# 设置有效长度\n",
    "valid_lens = torch.tensor([7, 3])\n",
    "# 创建DotProductAttention实例\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "# 将模型设置为评估模式\n",
    "attention.eval()\n",
    "# 计算注意力输出\n",
    "print(attention(queries, keys, values, valid_lens))\n",
    "\n",
    "# 使用show_heatmaps函数显示注意力权重的热图\n",
    "show_heatmaps(attention.attention_weights.reshape((1, 1, 20, 10)), xlabel='Keys', ylabel='Queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.多头注意力和自注意力\n",
    "\n",
    "自注意力是一种机制，用于计算序列中每个元素与其他元素之间的相关性（注意力权重），从而捕捉序列内部的依赖关系。多头注意力是一种多层次的注意力机制，它允许模型在多个不同的表示子空间中并行地学习信息。这可以提高模型捕获不同类型信息的能力。多头注意力是对自注意力的一种扩展，它通过并行运行多个自注意力机制（称为“头”），并将它们的结果拼接或加权组合，从而捕捉更丰富的特征。因此多头注意力的每个头本质上是一个自注意力机制。\n",
    "\n",
    "（1）用于变换查询、键、值的形状以适应多头注意力的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于变换查询、键、值的形状以适应多头注意力\n",
    "def transpose_qkv(X, num_heads):\n",
    "    # 将输入X变换为适合多头注意力的形状\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    # 展平前两个维度以进行批处理操作\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）用于变换多头注意力的输出形状的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于变换多头注意力的输出形状\n",
    "def transpose_output(X, num_heads):\n",
    "    # 将多头输出变换回原始形状\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    \n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）多头注意力的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多头注意力\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, \n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        # 设置多头的数量\n",
    "        self.num_heads = num_heads\n",
    "        # 初始化点积注意力模块\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        # 初始化查询、键、值的线性变换层\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        # 初始化输出的线性变换层\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        \n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # 将查询、键、值通过各自的线性层，并按照多头的方式进行变换\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "        print(\"\\n将查询、键、值通过各自的线性层，并按照多头的方式进行变换:\")\n",
    "        print(f'Q.shape = {queries.shape}\\nK.shape = {keys.shape}\\nV.shape = {values.shape}')\n",
    "        \n",
    "        # 如果提供了有效长度，则在多头注意力中应用掩蔽\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=0)\n",
    "        \n",
    "        # 计算注意力输出\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        print(\"\\n注意力输出:\")\n",
    "        print(output.shape)\n",
    "        # 将多头的输出变换回原始形状\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        print(\"\\n将多头的输出变换回原始形状:\")\n",
    "        print(output_concat.shape)\n",
    "        # 通过输出的线性层\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）多头注意力和自注意力测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape = torch.Size([2, 4, 100]) \n",
      "Y.shape = torch.Size([2, 6, 100]) \n",
      "\n",
      "将查询、键、值通过各自的线性层，并按照多头的方式进行变换:\n",
      "Q.shape = torch.Size([10, 4, 20])\n",
      "K.shape = torch.Size([10, 6, 20])\n",
      "V.shape = torch.Size([10, 6, 20])\n",
      "\n",
      "注意力输出:\n",
      "torch.Size([10, 4, 20])\n",
      "\n",
      "将多头的输出变换回原始形状:\n",
      "torch.Size([2, 4, 100])\n",
      "\n",
      "将查询、键、值通过各自的线性层，并按照多头的方式进行变换:\n",
      "Q.shape = torch.Size([10, 4, 20])\n",
      "K.shape = torch.Size([10, 4, 20])\n",
      "V.shape = torch.Size([10, 4, 20])\n",
      "\n",
      "注意力输出:\n",
      "torch.Size([10, 4, 20])\n",
      "\n",
      "将多头的输出变换回原始形状:\n",
      "torch.Size([2, 4, 100])\n",
      "多头注意力形状：torch.Size([2, 4, 100])\n",
      "自注意力形状：torch.Size([2, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_hiddens = 100\n",
    "num_heads = 5\n",
    "num_queries = 4\n",
    "num_kvpairs = 6  # 键值对数量\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "\n",
    "# 实例化多头注意力\n",
    "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5)\n",
    "\n",
    "attention.eval()\n",
    "# 创建查询和键值对的随机数据\n",
    "X = torch.ones(batch_size, num_queries, num_hiddens)\n",
    "Y = torch.ones(batch_size, num_kvpairs, num_hiddens)\n",
    "print(f'\\nX.shape = {X.shape} \\nY.shape = {Y.shape} ')\n",
    "\n",
    "# 打印多头注意力输出的形状\n",
    "mul_att_shape = attention(X, Y, Y, valid_lens).shape\n",
    "self_att_shape = attention(X, X, X, valid_lens).shape\n",
    "print(f'多头注意力形状：{mul_att_shape}')\n",
    "print(f'自注意力形状：{self_att_shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
